# Tema4
## Solución del problema 4
###### Adrián Montero Bonilla B88092
###### Alberto Arias Brenes B90639

A partir de la práctica E13 del curso de Modelos Probabilísticos de Señales y Sistemas se trabaja para obtener una solución programada de este problema. 
Es importante recordar que un proceso estocástico es en sí un proceso que está compuesto por un conjunto de variables aleatorias en el tiempo, útil para describir sistemas dinámicos, el problema que se solucionará se ejecuta a partir de una función dada y se determinará el promedio y la autocorrelación de este. 

Se tiene el siguiente proceso: 
X(t) = Ccos(Ωt + Θ)

Además se define que: 

E[C] = 5 y  𝜎^2  = 0.2, la variable aleatoria C es gaussiana

Ω  es una variable aleatoria uniforme distribuida en [2 𝜋 (59.1) , 2 𝜋 (60.1)]

Θ  es una variable aleatoria uniforme con intervalo [0 ,  𝜋/2 ]

Las tres variables aleatorias son estadísticamente independientes


### Parte A. Determinación del valor esperado de un proceso estocástico.

Se debe considerar que la variable aleatoria  Ω  es una constante y se obtiene el promedio de este proceso. Al indicar que esto es así, el proceso consta entonces de dos variables aleatorias, las funciones que le conforman variarán su amplitud y también fase, pero la frecuencia de todas estas funciones será igual.

Inicialmente se deben importar librerías necesarias para la implementación del código 
```
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import random
```

La librería numpy se utiliza para el manejo de arreglos matemáticos, stats contiene una gran cantidad de distribuciones, matplotlib se utilizará para generar gráficos y darles formato, la librería random para escoger un valor aleatorio en rangos determinados. 

Se definen las variables aleatorias, que son independientes entre sí, para comprender correctamente el desarrollo es importante mencionar que la definición de las variables C = C, Θ = vaTh y Ω = vcO, teniendo esto en cuenta se muestra la implementación en Python.

```
vaC = stats.norm(5, np.sqrt(0.2)) # Gaussiana
vaTh = stats.uniform(0, np.pi/2) # Uniformemente distribuida
vcO = random.uniform(2*np.pi*59.1, 2*np.pi*60.1) # Omega

# Creación del vector de tiempo
T = 200	  # número de elementos
t_final = 10 # tiempo en segundos
t = np.linspace(0, t_final, T)

# Inicialización del proceso aleatorio X(t) con N realizaciones
N = 20
X_t = np.empty((N, len(t)))	# N funciones del tiempo x(t) con T puntos

# Creación de las muestras del proceso x(t), son las realizaciones
for i in range(N):
	C = vaC.rvs()
	Th = vaTh.rvs()
	x_t = C * np.cos(vcO*t + Th)
	X_t[i,:] = x_t
	plt.plot(t, x_t)

# Promedio de las N realizaciones en cada instante (cada punto en t)
Prom = [np.mean(X_t[:,i]) for i in range(len(t))]
plt.plot(t, Prom, lw=6, label='Promedio de las N realizaciones') 

# Se grafica el resultado teórico del valor esperado
E = 10/np.pi * (np.cos(vcO*t) - np.sin(vcO*t)) #Esto viene de la solución a mano, teórica
plt.plot(t, E, '-.', lw=4, label='Resultado teórico del promedio')


# Mostrar las realizaciones, y su promedio calculado y teórico
plt.title('Realizaciones del proceso aleatorio $X(t)$')
plt.xlabel('$t$')
plt.ylabel('$x_i(t)$')
plt.legend()
plt.show()
```
Al correr el código, se tiene la escogencia de un valor de Ω = 373.4695, esto está dentro del rango de valores posibles
Se obtiene la siguiente gráfica:

**

Al utilizar las funciones de Python para encontrar el promedio de este proceso estocástico se puede observar que la función de promedio teórica, calza de una forma adecuada y aproximada al promedio de las realizaciones generadas.

Es bueno comprender que al notar esta concordancia, se puede comprobar que al ser estadísticamente independientes la función de densidad conjunta es la multiplicación de cada función de densidad individual de las variables aleatorias y que el promedio de este proceso irá variando en el tiempo de forma sinusoidal, aumentando o disminuyendo su valor de forma periódica.

Además, de la gráfica generada se pueden denotar aspectos de importancia; primero como se ha dicho antes se puede ver que las realizaciones del proceso poseen una misma frecuencia ya que este valor se ha definido constante, pero su amplitud y fase varían. Estas variaciones son pequeñas, esto responde a que para la amplitud (C) la desviación estándar es pequeña y es por esto que las funciones están muy juntas entre sí, dando con que el promedio también se ajuste bastante, que se vean tan juntas las funciones, igualmente la fase tiene un pequeño rango de cambio y siendo eso así, las variaciones de fase no se ven significativas.





### Parte B. Autocorrelación de un proceso estocástico. 

La realización de esta parte consistió en calcular la autocorrelación para el nuevo proceso aleatorio al considerar tanto a Ω como a Θ como constantes. Al hacer esto, hay que realizar el mismo procedimiento que se le hizo al proceso de la parte A pero esta vez para la nueva expresión de X(t) dada. 

![image](https://user-images.githubusercontent.com/93066389/142434066-062af162-953b-4e15-ab74-2445a043d52f.png)

```
# Variables aleatoria C
vaC = stats.norm(5, np.sqrt(0.2))
omega = 3 #Ahora tanto Omega como Theta son constantes, se escogen valores arbitrarios.
theta = 1

# Creación del vector de tiempo
T = 100	  # número de elementos
t_final = 10	# tiempo en segundos
t = np.linspace(0, t_final, T)

# Inicialización del proceso aleatorio X(t) con N realizaciones
N = 10
X_t = np.empty((N, len(t)))	# N funciones del tiempo x(t) con T puntos

# Creación de las muestras del proceso x(t)
# Nótese que ya que tenemos otro proceso aleatorio X(t) disitnto, hay que repetir
# los mismos pasos que se siguieron en la parte A pero para el nuevo proceso aleatorio.
for i in range(N):
	C = vaC.rvs()
	x_t = C * np.cos(omega*t + theta)
	X_t[i,:] = x_t
```

Una vez finalizado lo anterior, se procede a calcular la autocorrelación. Para esto, simplemente se deja el código tal y como se tenía en el archivo L4_base.py,pero se cambia la ecuación de Rxx por el dado en la solución del problema 4. 

![image](https://user-images.githubusercontent.com/93066389/142434814-4b7d19e1-b655-4357-8545-f8bd15968de0.png)

```
# T valores de desplazamiento tau
desplazamiento = np.arange(T)
taus = desplazamiento/t_final

# Inicialización de matriz de valores de correlación para las N funciones
corr = np.empty((N, len(desplazamiento)))

# Nueva figura para la autocorrelación
plt.figure()

# Cálculo de correlación para cada valor de t
for n in range(N):
	for i, tau in enumerate(desplazamiento):
		corr[n, i] = np.correlate(X_t[n,:], np.roll(X_t[n,:], tau))/T
	plt.plot(taus, corr[n,:])

# Valor teórico de correlación
# Aquí se cambia la ecuación de Rxx por la dada en el problema 4.
Rxx = 25.2*np.cos(omega*t+theta)*np.cos(omega*(t+taus)+theta)

# Gráficas de correlación para cada realización y la
plt.plot(taus, Rxx, '-.', lw=4, label='Correlación teórica')
plt.title('Funciones de autocorrelación de las realizaciones del proceso')
plt.xlabel(r'$\tau$')
plt.ylabel(r'$R_{WW}(\tau)$')
plt.legend()
plt.show()
```
Finalmente, se obtiene la gráfica resultante para la autocorrelación. 

![image](https://user-images.githubusercontent.com/93066389/142442476-35c3952e-d6f6-4cb0-bfd9-40351ed982d1.png)



